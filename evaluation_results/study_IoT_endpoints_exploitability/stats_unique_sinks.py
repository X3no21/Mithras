import shutil

import numpy as np
import pandas as pd
import os
import re

from scipy import stats
from scipy.stats.mstats import f_oneway

import matplotlib.pyplot as plt


original_vulns = {
    'DIR818L_FW105b01': 1,
    'DIR822B1_FW202KRb06': 3,
    'DIR822C1_FW303WWb04_i4sa_middle': 2,
    'DIR-860L_B1_FW203b03': 1,
    'DIR868LB1_FW203b01': 2,
    'DIR-880L_A1_FW107WWb08': 1,
    'DIR880A1_FW100b48': 1,
    'DIR-890L_REVA1_FW100b25': 1,
    'DIR890LA1_FW111b04': 1,
    'DIR822B1_FW202KRb06.bin': 1,
    'DIR846enFW100A53DLA-Retail': 4
}


def vargha_delaney_paired(x, y):
    more = same = 0.0
    for i in range(len(x)):
        if x[i] == y[i]:
            same += 1
        elif x[i] > y[i]:
            more += 1
    return (more + 0.5 * same) / len(x)


def compute_statistic_test(dict_for_table, type, row_name, rl_mean, random_mean):
    (w_rl, p_rl) = stats.shapiro(np.array(rl_mean) - np.mean(rl_mean))
    (w_random, p_random) = stats.shapiro(np.array(random_mean) - np.mean(random_mean))

    if p_rl > 0.05 and p_random > 0.05:
        _, p = f_oneway(rl_mean, random_mean)
        with open(os.path.join("stats_unique_sinks", f"stats_tests_{type}.txt"), "a+") as f:
            if p < 0.05:
                f.write(f"{row_name} - ANOVA: RL and Random approaches have different behaviors\n\n")
                eff_size = (np.mean(rl_mean) - np.mean(random_mean)) / np.sqrt(
                    np.std(np.array(rl_mean) ** 2 + np.std(random_mean) ** 2) / 2.0)
                if p < 0.05:
                    if np.abs(eff_size) < 0.2:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " N")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    elif np.abs(eff_size) < 0.5:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " S")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    elif np.abs(eff_size) < 0.8:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " M")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    else:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " L")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                else:
                    dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")))
                    dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
            else:
                f.write(f"{row_name} - ANOVA: RL and Random approaches perform the same\n\n")
                dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")))
                dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
    else:
        (t, p) = stats.wilcoxon(rl_mean, random_mean)
        with open(os.path.join("stats_unique_sinks", f"stats_tests_{type}.txt"), "a+") as f:
            if p < 0.05:
                f.write(f"{row_name} - WILCOXON: RL and Random approaches have different behaviors\n\n")
                eff_size = vargha_delaney_paired(rl_mean, random_mean)
                if p < 0.05:
                    if 2 * np.abs(eff_size - 0.5) < 0.147:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " N")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    elif 2 * np.abs(eff_size - 0.5) < 0.33:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " S")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    elif 2 * np.abs(eff_size - 0.5) < 0.474:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " M")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    else:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " L")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                else:
                    dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")))
                    dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
            else:
                f.write(f"{row_name} - WILCOXON: RL and Random approaches perform the same\n\n")
                dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")))
                dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))


def plot_distributions(sac_num_unique_sinks, random_num_unique_sinks, sac_num_exploits, random_num_exploits, unique_exploits_sac, unique_exploits_random):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))

    fontsize_x = 15
    fontsize_y = 15
    fontsize_legend = 12
    tick_labelsize = 15
    ax1.scatter(range(len(sac_num_unique_sinks)), sac_num_unique_sinks, label='SAC', color='b', linewidth=2)
    ax1.scatter(range(len(random_num_unique_sinks)), random_num_unique_sinks, label='Black-box Fuzzer', color='r', linewidth=2)
    ax1.set_xlabel('Episode', fontsize=fontsize_x)
    ax1.set_xticks(range(10))
    ax1.set_ylabel('Cumulative # Unique IoT APIs Reached', fontsize=fontsize_y)
    ax1.legend(loc='center left', fontsize=fontsize_legend)
    ax1.tick_params(axis='both', which='major', labelsize=tick_labelsize)
    ax1.grid(True)

    ax2.scatter(range(len(sac_num_exploits)), sac_num_exploits, label='SAC', color='b', linewidth=2)
    ax2.scatter(range(len(random_num_exploits)), random_num_exploits, label='Black-box Fuzzer', color='r', linewidth=2)
    ax2.set_xlabel('Episode', fontsize=fontsize_x)
    ax2.set_xticks(range(10))
    ax2.set_ylabel('Cumulative # Vulnerabilities Exploited', fontsize=fontsize_y)
    ax2.legend(loc='upper left', fontsize=fontsize_legend)
    ax2.tick_params(axis='both', which='major', labelsize=tick_labelsize)
    ax2.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join("stats_unique_sinks", "unique_apis_and_exploits_for_episode.png"), format='png')
    plt.close(fig)

    fig, ax = plt.subplots(figsize=(14, 5))

    bar_width = 0.2
    indices = np.arange(len(unique_exploits_sac))

    ax.bar(indices, [round(max(unique_exploits_sac[firmware_name])) for firmware_name in unique_exploits_sac], bar_width, label='SAC', color='b')
    ax.bar(indices + 1 * bar_width, [round(max(unique_exploits_random[firmware_name])) for firmware_name in unique_exploits_random], bar_width, label='Black-box Fuzzer', color='r')
    ax.bar(indices + 2 * bar_width, [original_vulns[firmware_name] for firmware_name in unique_exploits_random], bar_width, label='# Real Vulnerabilities', color='y')
    ax.set_xlabel('Firmware', fontsize=fontsize_x)
    app_labels = [f"Frmw {i + 1}" for i in range(10)]
    ax.set_xticks(range(10))
    ax.set_xticklabels(app_labels, fontsize=tick_labelsize)
    ax.set_ylabel('# Unique Vulnerabilities Exploited', fontsize=fontsize_y)
    ax.legend(loc='upper left', fontsize=fontsize_legend)
    ax.tick_params(axis='both', which='major', labelsize=tick_labelsize)
    ax.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join("stats_unique_sinks", "unique_exploits.png"), format='png')
    plt.close(fig)


if __name__ == "__main__":
    iterations = 10
    episodes = 10
    algos = ["random", "SAC"]

    shutil.rmtree("stats_unique_sinks")
    os.makedirs("stats_unique_sinks", exist_ok=True)
    stats_dict = dict()
    for firmware_name in os.listdir("./firmwares_data"):
        stats_dict[firmware_name] = {}
        for algo in algos:
            episode_stats = []
            stats_dict[firmware_name][algo] = {}
            iteration_stats_num_exploits = [[0 for _ in range(episodes)] for i in range(iterations)]
            iteration_stats_num_unique_exploits = [[set() for _ in range(episodes)] for i in range(iterations)]
            for episode in range(episodes):
                iteration_stats = []
                num_exploits = 0
                for iteration in range(iterations):
                    log_payload_folder = "results" + os.sep + firmware_name + os.sep + "payload" + os.sep + algo + os.sep + str(iteration) + os.sep + str(episode)
                    with open(os.path.join(log_payload_folder, "action_log.txt"), "r") as f:
                        num_api_called = 0
                        for line in f:
                            match = re.search(r"<EPISODE>.+</EPISODE><STEP>.+</STEP><ACT>.+</ACT><API>(.+)</API><PARAM>.+</PARAM><INPUT>.+</INPUT><ADD>.+</ADD><REW>.+</REW><DONE>.+</DONE><EXPLOIT>(.+)<EXPLOIT><INFO></INFO>", line)
                            if match:
                                api = match.group(1)
                                exploit = match.group(2)
                                num_api_called += 1
                                if exploit == "True":
                                    num_exploits += 1
                                    iteration_stats_num_unique_exploits[iteration][episode].add(api)
                        iteration_stats_num_exploits[iteration][episode] = num_exploits
                        iteration_stats.append(num_api_called)
                episode_stats.append(iteration_stats)
            mean_vector = []
            area_vector = []
            exploit_vector = []
            unique_exploit_vector = []
            for episode_stat in episode_stats:
                mean_vector.append(np.mean(episode_stat))

            for iteration_stat in iteration_stats_num_exploits:
                area_vector.append(np.trapz(iteration_stat, dx=1))

            for episode in range(episodes):
                exploits_for_episode = []
                unique_exploits_for_episode = []
                for iteration in range(iterations):
                    exploits_for_episode.append(iteration_stats_num_exploits[iteration][episode])
                    unique_exploits_for_episode.append(len(iteration_stats_num_unique_exploits[iteration][episode]))
                exploit_vector.append(np.mean(exploits_for_episode))
                unique_exploit_vector.append(np.mean(unique_exploits_for_episode))

            stats_dict[firmware_name][algo]["mean"] = mean_vector
            stats_dict[firmware_name][algo]["area"] = area_vector
            stats_dict[firmware_name][algo]["exploits"] = exploit_vector
            stats_dict[firmware_name][algo]["unique_exploits"] = unique_exploit_vector

    os.makedirs("stats_unique_sinks", exist_ok=True)
    for algo in algos:
        dict_for_table = dict()
        for firmware_name in stats_dict:
            dict_for_table[firmware_name] = stats_dict[firmware_name][algo]["mean"].copy()
            dict_for_table[firmware_name].append(sum(stats_dict[firmware_name][algo]["exploits"]))
        columns = []
        for i in range(episodes):
            columns.append(f"episode{i}")
        columns.append("num_vuln_exploited")
        df = pd.DataFrame.from_dict(dict_for_table, orient='index', columns=columns)
        df.reset_index(names=["firmware"]).to_csv(os.path.join("stats_unique_sinks", f"average_number_vuln_exploited_{algo}.csv"), index=False)

    for algo in algos:
        dict_for_table = dict()
        for firmware_name in stats_dict:
            dict_for_table[firmware_name] = stats_dict[firmware_name][algo]["area"]
        columns = []
        for i in range(episodes):
            columns.append(f"episode{i}")
        df = pd.DataFrame.from_dict(dict_for_table, orient='index', columns=columns)
        df.reset_index(names=["firmware"]).to_csv(os.path.join("stats_unique_sinks", f"average_auc_{algo}.csv"), index=False)

    dict_for_table = {firmware_name: [] for firmware_name in stats_dict}
    dict_for_table["Overall"] = []
    for firmware_name in stats_dict:
        rl_mean = stats_dict[firmware_name]["SAC"]["mean"]
        random_mean = stats_dict[firmware_name]["random"]["mean"]
        compute_statistic_test(dict_for_table, "mean", firmware_name, rl_mean, random_mean)

    for firmware_name in stats_dict:
        rl_mean = stats_dict[firmware_name]["SAC"]["area"]
        random_mean = stats_dict[firmware_name]["random"]["area"]
        compute_statistic_test(dict_for_table, "area", firmware_name, rl_mean, random_mean)

    for firmware_name in stats_dict:
        rl_mean = stats_dict[firmware_name]["SAC"]["exploits"]
        random_mean = stats_dict[firmware_name]["random"]["exploits"]
        compute_statistic_test(dict_for_table, "exploits", firmware_name, rl_mean, random_mean)

    for firmware_name in stats_dict:
        rl_mean = stats_dict[firmware_name]["SAC"]["unique_exploits"]
        random_mean = stats_dict[firmware_name]["random"]["unique_exploits"]
        compute_statistic_test(dict_for_table, "unique_exploits", firmware_name, rl_mean, random_mean)

    overall_firmwares_sac_mean = []
    for episode in range(episodes):
        mean_for_episode = []
        for firmware_name in stats_dict:
            mean_for_episode.append(np.mean(stats_dict[firmware_name]["SAC"]["mean"][episode]))
        overall_firmwares_sac_mean.append(np.mean(mean_for_episode))

    overall_firmwares_random_mean = []
    for episode in range(episodes):
        mean_for_episode = []
        for firmware_name in stats_dict:
            mean_for_episode.append(np.mean(stats_dict[firmware_name]["random"]["mean"][episode]))
        overall_firmwares_random_mean.append(np.mean(mean_for_episode))
    compute_statistic_test(dict_for_table, "overall_mean", "Overall", overall_firmwares_sac_mean, overall_firmwares_random_mean)

    overall_firmwares_sac_area = []
    for episode in range(episodes):
        mean_for_episode = []
        for firmware_name in stats_dict:
            mean_for_episode.append(np.mean(stats_dict[firmware_name]["SAC"]["area"][episode]))
        overall_firmwares_sac_area.append(np.mean(mean_for_episode))

    overall_firmwares_random_area = []
    for episode in range(episodes):
        mean_for_episode = []
        for firmware_name in stats_dict:
            mean_for_episode.append(np.mean(stats_dict[firmware_name]["random"]["area"][episode]))
        overall_firmwares_random_area.append(np.mean(mean_for_episode))
    compute_statistic_test(dict_for_table, "overall_area", "Overall", overall_firmwares_sac_area, overall_firmwares_random_area)

    overall_firmwares_sac_exploit = []
    for episode in range(episodes):
        mean_for_episode = []
        for firmware_name in stats_dict:
            mean_for_episode.append(np.mean(stats_dict[firmware_name]["SAC"]["exploits"][episode]))
        overall_firmwares_sac_exploit.append(np.mean(mean_for_episode))

    overall_firmwares_random_exploit = []
    for episode in range(episodes):
        mean_for_episode = []
        for firmware_name in stats_dict:
            mean_for_episode.append(np.mean(stats_dict[firmware_name]["random"]["exploits"][episode]))
        overall_firmwares_random_exploit.append(np.mean(mean_for_episode))
    compute_statistic_test(dict_for_table, "overall_exploits", "Overall", overall_firmwares_sac_exploit, overall_firmwares_random_exploit)

    overall_firmwares_sac_unique_exploit = []
    for episode in range(episodes):
        mean_for_episode = []
        for firmware_name in stats_dict:
            mean_for_episode.append(np.mean(stats_dict[firmware_name]["SAC"]["unique_exploits"][episode]))
        overall_firmwares_sac_unique_exploit.append(np.mean(mean_for_episode))

    overall_firmwares_random_unique_exploit = []
    for episode in range(episodes):
        mean_for_episode = []
        for firmware_name in stats_dict:
            mean_for_episode.append(np.mean(stats_dict[firmware_name]["random"]["unique_exploits"][episode]))
        overall_firmwares_random_unique_exploit.append(np.mean(mean_for_episode))
    compute_statistic_test(dict_for_table, "overall_unique_exploits", "Overall", overall_firmwares_sac_unique_exploit, overall_firmwares_random_unique_exploit)

    cumulative_overall_firmwares_sac_exploit = overall_firmwares_sac_exploit.copy()
    for i in range(1, len(overall_firmwares_sac_exploit)):
        cumulative_overall_firmwares_sac_exploit[i] = cumulative_overall_firmwares_sac_exploit[i] + cumulative_overall_firmwares_sac_exploit[i - 1]

    cumulative_overall_firmwares_random_exploit = overall_firmwares_random_exploit.copy()
    for i in range(1, len(overall_firmwares_random_exploit)):
        cumulative_overall_firmwares_random_exploit[i] = cumulative_overall_firmwares_random_exploit[i] + cumulative_overall_firmwares_random_exploit[i - 1]

    unique_exploit_sac = {firmware_name: stats_dict[firmware_name]['SAC']["unique_exploits"] for firmware_name in stats_dict}
    unique_exploit_random = {firmware_name: stats_dict[firmware_name]['random']["unique_exploits"] for firmware_name in stats_dict}
    plot_distributions(sorted(overall_firmwares_sac_mean), sorted(overall_firmwares_random_mean), cumulative_overall_firmwares_sac_exploit, cumulative_overall_firmwares_random_exploit, unique_exploit_sac, unique_exploit_random)

    df = pd.DataFrame.from_dict(dict_for_table, orient='index', columns=["mean_sac", "mean_random", "area_sac", "area_random", "successful_exploit_sac", "successful_exploit_random", "unique_successful_exploit_sac", "unique_successful_exploit_random"])
    df.reset_index(names=["firmware"]).to_csv(os.path.join("stats_unique_sinks", "final_table.csv"), index=False)