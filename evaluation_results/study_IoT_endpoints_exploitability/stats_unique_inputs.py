import numpy as np
import pandas as pd
import shutil
import os
import re

from scipy import stats
from scipy.stats.mstats import f_oneway


def vargha_delaney_paired(x, y):
    more = same = 0.0
    for i in range(len(x)):
        if x[i] == y[i]:
            same += 1
        elif x[i] > y[i]:
            more += 1
    return (more + 0.5 * same) / len(x)


def compute_statistic_test(dict_for_table, type, row_name, rl_mean, random_mean):
    (w_rl, p_rl) = stats.shapiro(np.array(rl_mean) - np.mean(rl_mean))
    (w_random, p_random) = stats.shapiro(np.array(random_mean) - np.mean(random_mean))

    if p_rl > 0.05 and p_random > 0.05:
        _, p = f_oneway(rl_mean, random_mean)
        with open(os.path.join("stats_unique_inputs", f"stats_tests_{type}.txt"), "a+") as f:
            if p < 0.05:
                f.write(f"{row_name} - ANOVA: RL and Random approaches have different behaviors\n\n")
                eff_size = (np.mean(rl_mean) - np.mean(random_mean)) / np.sqrt(
                    np.std(np.array(rl_mean) ** 2 + np.std(random_mean) ** 2) / 2.0)
                if p < 0.05:
                    if np.abs(eff_size) < 0.2:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " N")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    elif np.abs(eff_size) < 0.5:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " S")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    elif np.abs(eff_size) < 0.8:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " M")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    else:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " L")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                else:
                    dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")))
                    dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
            else:
                f.write(f"{row_name} - ANOVA: RL and Random approaches perform the same\n\n")
                dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")))
                dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
    else:
        (t, p) = stats.wilcoxon(rl_mean, random_mean)
        with open(os.path.join("stats_unique_inputs", f"stats_tests_{type}.txt"), "a+") as f:
            if p < 0.05:
                f.write(f"{row_name} - WILCOXON: RL and Random approaches have different behaviors\n\n")
                eff_size = vargha_delaney_paired(rl_mean, random_mean)
                if p < 0.05:
                    if 2 * np.abs(eff_size - 0.5) < 0.147:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " N")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    elif 2 * np.abs(eff_size - 0.5) < 0.33:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " S")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    elif 2 * np.abs(eff_size - 0.5) < 0.474:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " M")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                    else:
                        dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")) + " L")
                        dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
                else:
                    dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")))
                    dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))
            else:
                f.write(f"{row_name} - WILCOXON: RL and Random approaches perform the same\n\n")
                dict_for_table[row_name].append(str(format(np.mean(rl_mean), ".2f")))
                dict_for_table[row_name].append(str(format(np.mean(random_mean), ".2f")))


if __name__ == "__main__":
    iterations = 10
    episodes = 10
    algos = ["random", "SAC"]

    shutil.rmtree("stats_unique_inputs")
    os.makedirs("stats_unique_inputs", exist_ok=True)
    stats_dict = dict()
    for firmware_name in os.listdir("./firmwares_data"):
        stats_dict[firmware_name] = {}
        for algo in algos:
            episode_stats = []
            stats_dict[firmware_name][algo] = {}
            unique_inputs = [[set() for _ in range(episodes)] for _ in range(iterations)]
            iteration_stats_complete = [[0 for _ in range(episodes)] for i in range(iterations)]
            for episode in range(episodes):
                iteration_stats = []
                num_exploits = 0
                for iteration in range(iterations):
                    log_payload_folder = "results" + os.sep + firmware_name + os.sep + "payload" + os.sep + algo + os.sep + str(iteration) + os.sep + str(episode)
                    with open(os.path.join(log_payload_folder, "action_log.txt"), "r") as f:
                        num_api_called = 0
                        for line in f:
                            match = re.search(r"<EPISODE>.+</EPISODE><STEP>.+</STEP(><ACT>.+</ACT><API>.+</API><PARAM>.+</PARAM><INPUT>.+</INPUT><ADD>.+</ADD>)<REW>.+</REW><DONE>.+</DONE><EXPLOIT>(.+)<EXPLOIT><INFO></INFO>", line)
                            if match:
                                input_to_device = match.group(1)
                                exploit = match.group(2)
                                if input_to_device not in unique_inputs[iteration][episode]:
                                    num_api_called += 1
                                    unique_inputs[iteration][episode].add(input_to_device)
                                    if exploit == "True":
                                        num_exploits += 1
                        iteration_stats_complete[iteration][episode] = num_exploits
                        iteration_stats.append(num_api_called)
                episode_stats.append(iteration_stats)
            mean_vector = []
            area_vector = []
            exploit_vector = []
            for episode_stat in episode_stats:
                mean_vector.append(np.mean(episode_stat))

            for iteration_stat in iteration_stats_complete:
                area_vector.append(np.trapz(iteration_stat, dx=1))

            for episode in range(episodes):
                exploits_for_episode = []
                for iteration in range(iterations):
                    exploits_for_episode.append(iteration_stats_complete[episode][iteration])
                exploit_vector.append(np.mean(exploits_for_episode))

            stats_dict[firmware_name][algo]["mean"] = mean_vector
            stats_dict[firmware_name][algo]["area"] = area_vector
            stats_dict[firmware_name][algo]["exploits"] = exploit_vector

    os.makedirs("stats_unique_inputs", exist_ok=True)
    for algo in algos:
        dict_for_table = dict()
        for firmware_name in stats_dict:
            dict_for_table[firmware_name] = stats_dict[firmware_name][algo]["mean"].copy()
        columns = []
        for i in range(episodes):
            columns.append(f"episode{i}")
        df = pd.DataFrame.from_dict(dict_for_table, orient='index', columns=columns)
        df.reset_index(names=["firmware"]).to_csv(os.path.join("stats_unique_inputs", f"average_number_vuln_exploited_{algo}.csv"), index=False)

    for algo in algos:
        dict_for_table = dict()
        for firmware_name in stats_dict:
            dict_for_table[firmware_name] = stats_dict[firmware_name][algo]["area"]
        columns = []
        for i in range(episodes):
            columns.append(f"episode{i}")
        df = pd.DataFrame.from_dict(dict_for_table, orient='index', columns=columns)
        df.reset_index(names=["firmware"]).to_csv(os.path.join("stats_unique_inputs", f"average_auc_{algo}.csv"), index=False)

    dict_for_table = {firmware_name: [] for firmware_name in stats_dict}
    dict_for_table["Overall"] = []
    for firmware_name in stats_dict:
        rl_mean = stats_dict[firmware_name]["SAC"]["mean"]
        random_mean = stats_dict[firmware_name]["random"]["mean"]
        compute_statistic_test(dict_for_table, "mean", firmware_name, rl_mean, random_mean)

    for firmware_name in stats_dict:
        rl_mean = stats_dict[firmware_name]["SAC"]["area"]
        random_mean = stats_dict[firmware_name]["random"]["area"]
        compute_statistic_test(dict_for_table, "area", firmware_name, rl_mean, random_mean)

    overall_firmwares_sac_mean = [np.mean(stats_dict[firmware_name]["SAC"]["mean"]) for firmware_name in stats_dict]
    overall_firmwares_random_mean = [np.mean(stats_dict[firmware_name]["random"]["mean"]) for firmware_name in stats_dict]
    compute_statistic_test(dict_for_table, "overall_mean", "Overall", overall_firmwares_sac_mean, overall_firmwares_random_mean)

    overall_firmwares_sac_area = [np.mean(stats_dict[firmware_name]["SAC"]["area"]) for firmware_name in stats_dict]
    overall_firmwares_random_area = [np.mean(stats_dict[firmware_name]["random"]["area"]) for firmware_name in stats_dict]
    compute_statistic_test(dict_for_table, "overall_area", "Overall", overall_firmwares_sac_area, overall_firmwares_random_area)

    df = pd.DataFrame.from_dict(dict_for_table, orient='index', columns=["mean_sac", "mean_random", "area_sac", "area_random"])
    df.reset_index(names=["firmware"]).to_csv(os.path.join("stats_unique_inputs", "final_table.csv"), index=False)